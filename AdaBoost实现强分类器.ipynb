{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier#adaboost引入方法\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_gaussian_quantiles#造数据\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 设置属性防止中文乱码\n",
    "mpl.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(t):\n",
    "    return np.sum([-p*np.log2(p) for p in t if p!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h1(y=[1,1,1,-1,-1,-1,1,1,1,-1],w=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]):\n",
    "    #类似引用\n",
    "    p1=np.sum(np.asarray(w)[np.asarray(y)==1])\n",
    "    p2=1-p1\n",
    "    return entropy([p1,p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y=[1,1,1,-1,-1,-1,1,1,1,-1]\n",
    "# w=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]\n",
    "# np.sum(np.asarray(w)[np.asarray(y)==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h2(split=3,y=[1,1,1,-1,-1,-1,1,1,1,-1],w=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]):\n",
    "    y=np.asarray(y)\n",
    "    w=np.asarray(w)\n",
    "    #计算左边的相关信息\n",
    "    data_y=y[:split]\n",
    "    data_w=w[:split]\n",
    "    p10=np.sum(data_w)\n",
    "    p11=np.sum(data_w[data_y==1])/p10\n",
    "    p12=1-p11\n",
    "    h1=entropy([p11,p12])\n",
    "    \n",
    "    #计算右侧的相关信息\n",
    "    data_y=y[split:]\n",
    "    data_w=w[split:]\n",
    "    p20=np.sum(data_w)\n",
    "    p21=np.sum(data_w[data_y==1])/p20\n",
    "    p22=1-p21\n",
    "    h2=entropy([p21,p22])\n",
    "    \n",
    "    #计算划分的条件熵\n",
    "    return p10*h1+p20*h2\n",
    "\n",
    "def h3(errs=[],w=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]):\n",
    "    w=np.asarray(w)\n",
    "    #计算错误率\n",
    "    e=np.sum([w[i] for i in errs])\n",
    "    #计算alpha\n",
    "    alpha=0.5*np.log2((1-e)/e)\n",
    "    #获取预测成功的样本下标\n",
    "    trues=[i for i in range(len(w)) if i not in errs]\n",
    "    #对预测成功的样本权重进行更新\n",
    "    w[trues]=w[trues]*(np.e**(-alpha))\n",
    "    #对预测失败的样本权重进行标注\n",
    "    w[errs]=w[errs]*(np.e**(-alpha))\n",
    "    # 做一个归一化，保证np.sum(w) == 1.0\n",
    "    w = w / np.sum(w)\n",
    "\n",
    "    return e,alpha,w\n",
    "    \n",
    "def calcl():\n",
    "    print('第一个子模型的选择：')\n",
    "    print('='*100)\n",
    "    a=h1()\n",
    "    print('原始数据的信息熵：{}'.format(a))\n",
    "    print('以2.5划分的信息增益'.format(a-h2(split=3)))\n",
    "    print('以5.5划分的信息增益'.format(a-h2(split=6)))\n",
    "    print('以8.5划分的信息增益'.format(a-h2(split=9)))\n",
    "    err,alpha1,w=h3(errs=[6,7,8])\n",
    "    print(\"第1个子模型的误差率:{}\".format(err))\n",
    "    print(\"第1个子模型的权重系数:{}\".format(alpha1))\n",
    "    print(\"第1个子模型更新的样本权重系数:\\n{}\\n\".format(w))\n",
    "    \n",
    "    \n",
    "    print(\"第二个子模型的选择\")\n",
    "    print(\"=\" * 100)\n",
    "    a = h1(w=w)\n",
    "    print(\"原始数据的信息熵:{}\".format(a))\n",
    "    print(\"以2.5划分的信息增益:{}\".format(a - h2(split=3, w=w)))\n",
    "    print(\"以5.5划分的信息增益:{}\".format(a - h2(split=6, w=w)))\n",
    "    print(\"以8.5划分的信息增益:{}\".format(a - h2(split=9, w=w)))\n",
    "    err, alpha2, w = h3(errs=[0, 1, 2, 9], w=w)\n",
    "    print(\"第2个子模型的误差率:{}\".format(err))\n",
    "    print(\"第2个子模型的权重系数:{}\".format(alpha2))\n",
    "    print(\"第2个子模型更新的样本权重系数:\\n{}\\n\".format(w))\n",
    "\n",
    "    print(\"第三个子模型的选择\")\n",
    "    print(\"=\" * 100)\n",
    "    a = h1(w=w)\n",
    "    print(\"原始数据的信息熵:{}\".format(a))\n",
    "    print(\"以2.5划分的信息增益:{}\".format(a - h2(split=3, w=w)))\n",
    "    print(\"以5.5划分的信息增益:{}\".format(a - h2(split=6, w=w)))\n",
    "    print(\"以8.5划分的信息增益:{}\".format(a - h2(split=9, w=w)))\n",
    "    err, alpha3, w = h3(errs=[3, 4, 5], w=w)\n",
    "    print(\"第3个子模型的误差率:{}\".format(err))\n",
    "    print(\"第3个子模型的权重系数:{}\".format(alpha3))\n",
    "    print(\"第3个子模型更新的样本权重系数:\\n{}\\n\".format(w))\n",
    "    \n",
    "    print(\"第四个子模型的选择\")\n",
    "    print(\"=\" * 100)\n",
    "    a = h1(w=w)\n",
    "    print(\"原始数据的信息熵:{}\".format(a))\n",
    "    print(\"以2.5划分的信息增益:{}\".format(a - h2(split=3, w=w)))\n",
    "    print(\"以5.5划分的信息增益:{}\".format(a - h2(split=6, w=w)))\n",
    "    print(\"以8.5划分的信息增益:{}\".format(a - h2(split=9, w=w)))\n",
    "    err, alpha4, w = h3(errs=[6, 7, 8], w=w)\n",
    "    print(\"第4个子模型的误差率:{}\".format(err))\n",
    "    print(\"第4个子模型的权重系数:{}\".format(alpha4))\n",
    "    print(\"第4个子模型更新的样本权重系数:\\n{}\\n\".format(w))\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(\"1:{}\".format(alpha1 - alpha2 + alpha3 + alpha4))\n",
    "    print(\"2:{}\".format(-alpha1 - alpha2 + alpha3 - alpha4))\n",
    "    print(\"3:{}\".format(-alpha1 + alpha2 + alpha3 - alpha4))\n",
    "    print(\"4:{}\".format(-alpha1 + alpha2 - alpha3 - alpha4))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一个子模型的选择：\n",
      "====================================================================================================\n",
      "原始数据的信息熵：0.9709505944546686\n",
      "以2.5划分的信息增益\n",
      "以5.5划分的信息增益\n",
      "以8.5划分的信息增益\n",
      "第1个子模型的误差率:0.30000000000000004\n",
      "第1个子模型的权重系数:0.6111962106682238\n",
      "第1个子模型更新的样本权重系数:\n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "\n",
      "第二个子模型的选择\n",
      "====================================================================================================\n",
      "原始数据的信息熵:0.9709505944546686\n",
      "以2.5划分的信息增益:0.2812908992306925\n",
      "以5.5划分的信息增益:0.046439344671015514\n",
      "以8.5划分的信息增益:0.1444843438056279\n",
      "第2个子模型的误差率:0.4\n",
      "第2个子模型的权重系数:0.292481250360578\n",
      "第2个子模型更新的样本权重系数:\n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "\n",
      "第三个子模型的选择\n",
      "====================================================================================================\n",
      "原始数据的信息熵:0.9709505944546686\n",
      "以2.5划分的信息增益:0.2812908992306925\n",
      "以5.5划分的信息增益:0.046439344671015514\n",
      "以8.5划分的信息增益:0.14448434380562802\n",
      "第3个子模型的误差率:0.3\n",
      "第3个子模型的权重系数:0.611196210668224\n",
      "第3个子模型更新的样本权重系数:\n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "\n",
      "第四个子模型的选择\n",
      "====================================================================================================\n",
      "原始数据的信息熵:0.9709505944546686\n",
      "以2.5划分的信息增益:0.2812908992306925\n",
      "以5.5划分的信息增益:0.046439344671015514\n",
      "以8.5划分的信息增益:0.14448434380562802\n",
      "第4个子模型的误差率:0.3\n",
      "第4个子模型的权重系数:0.611196210668224\n",
      "第4个子模型更新的样本权重系数:\n",
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "\n",
      "====================================================================================================\n",
      "1:1.5411073816440939\n",
      "2:-0.9036774610288019\n",
      "3:-0.31871496030764584\n",
      "4:-1.5411073816440939\n"
     ]
    }
   ],
   "source": [
    "calcl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import tree\n",
    "# import pydotplus \n",
    "# dot_data = tree.export_graphviz(model, out_file=None) \n",
    "# graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "# # graph.write_pdf(\"iris2.pdf\") \n",
    "# graph.write_png(\"0616.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
